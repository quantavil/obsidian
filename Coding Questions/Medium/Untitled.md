## **Approach 1: Recursive with backtracking (implicit stack)**

___

**Big-O:**

-   **Time:** `O(N*N!)`
    
    -   **Why O(N\*N!) and not just O(N!) ?**  
        Many people are debating in the solution tab whether time-complexity should be `O(N!)` or `O(N * N!)`. Below are two intuitive arguments as to why it should be `O(N*N!)`. Let's forget for a while about the recursive nature of the algorithm and examine the **N-ary, recursive, space-tree** that is generated by the recursive algorithm.
        
        ![image](https://assets.leetcode.com/users/images/ac9c35dc-89b8-4860-b08c-d2f60859e43e_1609289801.6830964.png)
        
    
    1.  In order to reaverse the tree, will visit each node once, we know very well that would cost us `O(N)` in a binary tree and `O(E+V)` in an N-ary tree where V = vertices and E = edges (or number of children). Now for the \[1,2,3\] example shown in the sketch, we can see there is a total of 16 nodes/verticies and that |E| varies from level to level with an upper limit of N and a lower limit of 1.
        
        -   So, we can say roughly O(E+V) = a little more than 16
        -   O(N!) on the other hand = 6
        -   whereas, O(N_N!) = 3_6 = 18
    2.  Another way of looking at is we know from set theory that there are N! permutations of a list of size N. We also know that the permutations are going to be the leaves of the tree, which means we will have N! leaves. In order to get to each one of those leaves, we had to go through N calls. That's O(N\*N!). Again a little more than the total number of nodes because some nodes are shared among more than one path.
        
-   **Space:** `O(N!)`
    
    -   Because you still need to store the permutations and there are N! of them even if the depth of the stack is maxed out at N+1 (depth of the recursion space-tree is also N+1). See figure below.

**Code:**

```python
def permute(self, nums):
# helper
def recursive(nums, perm=[], res=[]):
if not nums: # -- NOTE [1] 
res.append(perm[::]) #  -- NOTE [2] - append a copy of the perm at the leaf before we start popping/backtracking

for i in range(len(nums)): # [1,2,3]
newNums = nums[:i] + nums[i+1:]
perm.append(nums[i])
recursive(newNums, perm, res) # - recursive call will make sure I reach the leaf
perm.pop() # -- NOTE [3] 
return res

return recursive(nums)

# NOTE [1]:
# --------
# nums is empty at the leaf of the recursive tree

# NOTE [2]:
# --------
# at the leaf -> we know we have exaushted one path/permutation (each path is a permutation in a recursive tree)
# reason why we are copying here is because at lists are passed by reference and since we are maintaining only one path/perm variable throughput, we are gonna be modifiying that path variable (popping it to be precise) in order to revert the path to a previous state (aka parent node) in preperation to make a lateral/horizontal move to a sibling node. See explanation below for further understanding.

# NOTE [3]:
# ---------
# See below
```

**NOTE \[3\] Explained further : Why do we need to backtrack?**

-   Notice how in the code above, there is only one variable path (or perm) throughout the problem. This variable is passed to one recursive call after another recursive call as we move from the input (the root of the tree) to the leaf (the permutation) and obvioulsy it gets modified multiple times along the way. As we keep building the path (or perm). It goes from `[ ] -> [1,2] -> [1,2,3]` as you can see in the left-most branch. However, what actually happens is that everytime we append a number to the path, **we are actively changing the path from previous recursive states as well**, since all of these point to the same path list and are not independent states/copies. Since effectively all these aliases are pointing to the same memory location, any change to the variable are echoed to all of its aliases. This can be problematic because it alters the the previous states. See below for visual illustration of the problem.

![image](https://assets.leetcode.com/users/images/2dad4626-ba5b-4d8f-adcb-90249a1eddb4_1609299083.319523.png)

-   To overcome this problem, we need to backtrack. It's tempting to think backtracking is needed only in situations where we encounter an obstacle while building/searching for the solution (such as hitting a wall while traversing a maze), however, backtracking as a technique has broader scope than just that. Any situation where we might need to access a previous state of a variable that keeps changing during the execution of the program requires backtracking. As mentioned earlier an coming across an obstacle in a maze (or anything that renders the path being explored invalid) is NOT the only incident backtracking is called upon. Backtracking would still be required even if the current path being explored is valid, in order to explore the next path. Think of a parent node from which two child nodes diverge. After exploring the first child, we need to backtrack to parent to investigate the sibling node (other child). This situation takes place in our space-tree. See sketch below.

![image](https://assets.leetcode.com/users/images/ea5e3934-308b-486b-bd9d-ba5d84972c93_1609311308.955607.png)

-   As you can see in the sketch above, by the time we reach node B, the path = \[1,2,3\]. These changes are echoed up to the parent node and even all the way up to the root if we don't backtrack which will ruin subsequent paths (ex: ParentNode -> node C) is missed up. This can be alleviated by popping the path after each recursive call as we did in our code.
    
    ```python
    for i in range(len(nums)): # [1,2,3]
    newNums = nums[:i] + nums[i+1:]
    perm.append(nums[i])
    recursive(newNums, perm, res) 
    perm.pop() # -- BACKTRACK
    ```
    
-   It's also worth-mentioning that backtracking was needed here because of the branching nature of the space-tree. Backtracking won't be required if the recursive algorithm produces a linked-list rather than a space-tree. An example of such algorithm is recursively summing up numbers from 0 -> N
    
    ```python
    def sumPosNumLessThanN(N, res=0):
    if N == 0:
    return res
    else:
    res = 1 + sumPosNumLessThanN(N-1)
    return res
    ```
    
    The recursive algorithm above produces a chain of nodes (no branching):  
    ![image](https://assets.leetcode.com/users/images/65a431a3-c09d-4926-b431-8df5eb2a4cf3_1609312872.9623408.png)
    

**NOTE \[2\] Explained further : Why do we need to copy?**

-   You probably have guessed it by now. As shown above, due to the constantly changing state of our data/variables, we need to append a copy of the path `res.append(path[::])` at the leaf, instead of appending the path itself. The reason being that lists are mutable and are passed by reference, so even after appending a path to our result list, that path will still be affected by any changes to its aliases (will be afftected by all the poppping and backtracking taking place) and by the time our recursion calls make their way to the top/root, the path will be empty `path = [ ]`

**Backtracking seems like a pain in the a$$. Is there a way around it?**

-   Glad you asked, yes, there is! We can avoid backtracking all together with a little bit of book-keeping. Instead of having to backtrack to revert to a previous state of the data/variables, we could save snapshots of the data/variables at each step along the way so that we never have to manually backtrack. This can be done either recursively or iteratively by passing a copy of our data. See Approach 2 for recursive without backtracking, and Approach 3 for an itertaive solution without backtracking below.  
    .  
    .